# scripts/generate_better.py
import torch
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent))

from src.models.transformer import ColorTransformer
from src.data.tokenizer import ColorTokenizer

def generate_with_params(prompt, temperature, top_k):
    """FarklÄ± parametrelerle Ã¼retim yap"""
    input_ids = tokenizer.encode(prompt, add_special_tokens=True)
    input_tensor = torch.tensor([input_ids])
    
    # top_k vocabulary boyutundan bÃ¼yÃ¼k olamaz!
    vocab_size = tokenizer.vocab_size
    if top_k > vocab_size:
        print(f"âš ï¸ top_k={top_k} > vocab_size={vocab_size}, dÃ¼zeltiliyor...")
        top_k = vocab_size
    
    with torch.no_grad():
        generated = model.generate(
            input_tensor,
            max_length=8,
            temperature=temperature,
            top_k=top_k,
            eos_token_id=tokenizer.word2idx[tokenizer.eos_token]
        )
    
    return tokenizer.decode(generated[0].tolist())

# Model ve tokenizer'Ä± yÃ¼kle
print("âœ… Tokenizer yÃ¼kleniyor...")
tokenizer = ColorTokenizer()
tokenizer.load(Path("data/processed/tokenizer.json"))
print(f"   Vocabulary size: {tokenizer.vocab_size}")

print("\nâœ… Model yÃ¼kleniyor...")
model = ColorTransformer(
    vocab_size=tokenizer.vocab_size,
    d_model=64,
    n_heads=4,
    n_layers=2,
    d_ff=128,
    max_seq_len=20
)
checkpoint = torch.load("experiments/exp_20260213_204243/checkpoints/best.pt", map_location='cpu')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()
print(f"   Model epoch: {checkpoint['epoch']}")

# Test prompts
prompts = ["red apple", "blue sky", "green forest"]

print("\nğŸ”¬ PARAMETRE TESTÄ°")
print("="*60)

for prompt in prompts:
    print(f"\nğŸ“ Prompt: {prompt}")
    print("-"*40)
    
    # FarklÄ± parametre kombinasyonlarÄ±
    params_list = [
        (0.3, 10, "Kesin (dÃ¼ÅŸÃ¼k temperature, az Ã§eÅŸitlilik)"),
        (0.8, 40, "Normal (orta temperature, orta Ã§eÅŸitlilik)"),
        (1.2, 50, "YaratÄ±cÄ± (yÃ¼ksek temperature, Ã§ok Ã§eÅŸitlilik)"),
        (0.5, 5,  "Ã‡ok Kesin (Ã§ok dÃ¼ÅŸÃ¼k Ã§eÅŸitlilik)"),
        (1.5, 70, "Ã‡ok YaratÄ±cÄ± (Ã§ok yÃ¼ksek temperature)"),
    ]
    
    for temp, k, desc in params_list:
        try:
            result = generate_with_params(prompt, temp, k)
            print(f"  {desc}: {result}")
        except Exception as e:
            print(f"  {desc}: HATA - {e}")

print("\nâœ… Test tamamlandÄ±!")